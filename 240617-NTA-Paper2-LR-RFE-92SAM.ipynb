{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b3bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries to open data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statistics import mean as stat_mean\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef4e76",
   "metadata": {},
   "source": [
    "### One vs all classification: for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9cef7a",
   "metadata": {},
   "source": [
    "### Normalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3c204",
   "metadata": {},
   "source": [
    "#### For AFFF-GW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a4a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c1723c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: AFFF-GW\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (AFFF-GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc43a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79dc55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "#print(data_1)\n",
    "#data_1 = pd.DataFrame(data_1)\n",
    "#data_1.to_csv('log10_dat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0132b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cf4c103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.842 (0.056)\n",
      ">2 0.841 (0.072)\n",
      ">3 0.877 (0.091)\n",
      ">4 0.881 (0.099)\n",
      ">5 0.862 (0.098)\n",
      ">6 0.880 (0.100)\n",
      ">7 0.894 (0.105)\n",
      ">8 0.919 (0.107)\n",
      ">9 0.916 (0.106)\n",
      ">10 0.912 (0.101)\n",
      ">11 0.934 (0.079)\n",
      ">12 0.930 (0.101)\n",
      ">13 0.926 (0.101)\n",
      ">14 0.934 (0.084)\n",
      ">15 0.926 (0.096)\n",
      ">16 0.926 (0.092)\n",
      ">17 0.923 (0.096)\n",
      ">18 0.919 (0.103)\n",
      ">19 0.919 (0.103)\n",
      ">20 0.923 (0.096)\n",
      ">21 0.923 (0.096)\n",
      ">22 0.927 (0.092)\n",
      ">23 0.927 (0.092)\n",
      ">24 0.930 (0.083)\n",
      ">25 0.930 (0.083)\n",
      ">26 0.930 (0.083)\n",
      ">27 0.930 (0.083)\n",
      ">28 0.927 (0.082)\n",
      ">29 0.930 (0.083)\n",
      ">30 0.930 (0.083)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d474bf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 24.000\n",
      "Column: 1, Selected True, Rank: 1.000\n",
      "Column: 2, Selected True, Rank: 1.000\n",
      "Column: 3, Selected False, Rank: 15.000\n",
      "Column: 4, Selected False, Rank: 6.000\n",
      "Column: 5, Selected False, Rank: 7.000\n",
      "Column: 6, Selected True, Rank: 1.000\n",
      "Column: 7, Selected False, Rank: 22.000\n",
      "Column: 8, Selected False, Rank: 21.000\n",
      "Column: 9, Selected True, Rank: 1.000\n",
      "Column: 10, Selected False, Rank: 5.000\n",
      "Column: 11, Selected False, Rank: 8.000\n",
      "Column: 12, Selected True, Rank: 1.000\n",
      "Column: 13, Selected False, Rank: 16.000\n",
      "Column: 14, Selected False, Rank: 14.000\n",
      "Column: 15, Selected False, Rank: 4.000\n",
      "Column: 16, Selected True, Rank: 1.000\n",
      "Column: 17, Selected False, Rank: 12.000\n",
      "Column: 18, Selected False, Rank: 9.000\n",
      "Column: 19, Selected False, Rank: 18.000\n",
      "Column: 20, Selected False, Rank: 20.000\n",
      "Column: 21, Selected False, Rank: 13.000\n",
      "Column: 22, Selected True, Rank: 1.000\n",
      "Column: 23, Selected False, Rank: 19.000\n",
      "Column: 24, Selected False, Rank: 11.000\n",
      "Column: 25, Selected False, Rank: 2.000\n",
      "Column: 26, Selected False, Rank: 23.000\n",
      "Column: 27, Selected False, Rank: 3.000\n",
      "Column: 28, Selected False, Rank: 17.000\n",
      "Column: 29, Selected False, Rank: 10.000\n",
      "Feature Name: 390.964442/9.69, Index: 1, Rank: 1.000\n",
      "Feature Name: 218.986076/7.21, Index: 2, Rank: 1.000\n",
      "Feature Name: 529.279112/8.06, Index: 6, Rank: 1.000\n",
      "Feature Name: 341.160715/9.2, Index: 9, Rank: 1.000\n",
      "Feature Name: 241.180448/9.53, Index: 12, Rank: 1.000\n",
      "Feature Name: 295.263376/19.32, Index: 16, Rank: 1.000\n",
      "Feature Name: 132.056597/7.15, Index: 22, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='newton-cg', C=100, penalty='l2'), n_features_to_select=7)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81da5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_GW_NEW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd47e20",
   "metadata": {},
   "source": [
    "#### For LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "368d9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0160806e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: LL\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (GW, LL, BL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69e86b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc1f5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "#print(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6b92430",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30, 0, -10):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bc8af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 0.949 (0.073)\n",
      ">20 0.949 (0.073)\n",
      ">10 0.927 (0.081)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "719769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c32bd4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.866 (0.078)\n",
      ">2 0.899 (0.079)\n",
      ">3 0.892 (0.083)\n",
      ">4 0.903 (0.093)\n",
      ">5 0.913 (0.098)\n",
      ">6 0.917 (0.095)\n",
      ">7 0.931 (0.082)\n",
      ">8 0.916 (0.091)\n",
      ">9 0.920 (0.079)\n",
      ">10 0.927 (0.081)\n",
      ">11 0.931 (0.082)\n",
      ">12 0.939 (0.070)\n",
      ">13 0.943 (0.070)\n",
      ">14 0.950 (0.060)\n",
      ">15 0.950 (0.060)\n",
      ">16 0.950 (0.060)\n",
      ">17 0.949 (0.060)\n",
      ">18 0.956 (0.072)\n",
      ">19 0.960 (0.065)\n",
      ">20 0.949 (0.073)\n",
      ">21 0.949 (0.073)\n",
      ">22 0.953 (0.073)\n",
      ">23 0.949 (0.073)\n",
      ">24 0.945 (0.073)\n",
      ">25 0.949 (0.073)\n",
      ">26 0.949 (0.073)\n",
      ">27 0.949 (0.073)\n",
      ">28 0.949 (0.073)\n",
      ">29 0.949 (0.073)\n",
      ">30 0.949 (0.073)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df4de242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 12.000\n",
      "Column: 1, Selected False, Rank: 3.000\n",
      "Column: 2, Selected False, Rank: 11.000\n",
      "Column: 3, Selected False, Rank: 7.000\n",
      "Column: 4, Selected False, Rank: 17.000\n",
      "Column: 5, Selected False, Rank: 9.000\n",
      "Column: 6, Selected False, Rank: 13.000\n",
      "Column: 7, Selected False, Rank: 20.000\n",
      "Column: 8, Selected False, Rank: 14.000\n",
      "Column: 9, Selected True, Rank: 1.000\n",
      "Column: 10, Selected True, Rank: 1.000\n",
      "Column: 11, Selected False, Rank: 16.000\n",
      "Column: 12, Selected False, Rank: 2.000\n",
      "Column: 13, Selected False, Rank: 24.000\n",
      "Column: 14, Selected False, Rank: 15.000\n",
      "Column: 15, Selected True, Rank: 1.000\n",
      "Column: 16, Selected False, Rank: 4.000\n",
      "Column: 17, Selected False, Rank: 19.000\n",
      "Column: 18, Selected False, Rank: 18.000\n",
      "Column: 19, Selected False, Rank: 25.000\n",
      "Column: 20, Selected False, Rank: 21.000\n",
      "Column: 21, Selected False, Rank: 8.000\n",
      "Column: 22, Selected False, Rank: 27.000\n",
      "Column: 23, Selected False, Rank: 5.000\n",
      "Column: 24, Selected True, Rank: 1.000\n",
      "Column: 25, Selected False, Rank: 22.000\n",
      "Column: 26, Selected False, Rank: 10.000\n",
      "Column: 27, Selected False, Rank: 6.000\n",
      "Column: 28, Selected False, Rank: 26.000\n",
      "Column: 29, Selected False, Rank: 23.000\n",
      "Feature Name: 341.160715/9.2, Index: 9, Rank: 1.000\n",
      "Feature Name: 251.164574/8.66, Index: 10, Rank: 1.000\n",
      "Feature Name: 301.215668/17.74, Index: 15, Rank: 1.000\n",
      "Feature Name: 361.202243/9.92, Index: 24, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(estimator=LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2'), n_features_to_select=4)\n",
    "rfe.fit(data_1,target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d410a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_LL.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f8bceb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 12.000\n",
      "Column: 1, Selected False, Rank: 3.000\n",
      "Column: 2, Selected False, Rank: 11.000\n",
      "Column: 3, Selected False, Rank: 7.000\n",
      "Column: 4, Selected False, Rank: 17.000\n",
      "Column: 5, Selected False, Rank: 9.000\n",
      "Column: 6, Selected False, Rank: 13.000\n",
      "Column: 7, Selected False, Rank: 20.000\n",
      "Column: 8, Selected False, Rank: 14.000\n",
      "Column: 9, Selected True, Rank: 1.000\n",
      "Column: 10, Selected True, Rank: 1.000\n",
      "Column: 11, Selected False, Rank: 16.000\n",
      "Column: 12, Selected False, Rank: 2.000\n",
      "Column: 13, Selected False, Rank: 24.000\n",
      "Column: 14, Selected False, Rank: 15.000\n",
      "Column: 15, Selected True, Rank: 1.000\n",
      "Column: 16, Selected False, Rank: 4.000\n",
      "Column: 17, Selected False, Rank: 19.000\n",
      "Column: 18, Selected False, Rank: 18.000\n",
      "Column: 19, Selected False, Rank: 25.000\n",
      "Column: 20, Selected False, Rank: 21.000\n",
      "Column: 21, Selected False, Rank: 8.000\n",
      "Column: 22, Selected False, Rank: 27.000\n",
      "Column: 23, Selected False, Rank: 5.000\n",
      "Column: 24, Selected True, Rank: 1.000\n",
      "Column: 25, Selected False, Rank: 22.000\n",
      "Column: 26, Selected False, Rank: 10.000\n",
      "Column: 27, Selected False, Rank: 6.000\n",
      "Column: 28, Selected False, Rank: 26.000\n",
      "Column: 29, Selected False, Rank: 23.000\n",
      "Feature Name: 341.160715/9.2, Index: 9, Rank: 1.000\n",
      "Feature Name: 251.164574/8.66, Index: 10, Rank: 1.000\n",
      "Feature Name: 301.215668/17.74, Index: 15, Rank: 1.000\n",
      "Feature Name: 361.202243/9.92, Index: 24, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='newton-cg', C=100, penalty='l2'), n_features_to_select=4)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77cece",
   "metadata": {},
   "source": [
    "### For BL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9f557a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6998acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: BL\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf6866de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df1e2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "#print(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81c39450",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30,0,-10):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da566720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 0.964 (0.058)\n",
      ">20 0.946 (0.061)\n",
      ">10 0.906 (0.082)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a46cb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62c7326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.856 (0.063)\n",
      ">2 0.888 (0.110)\n",
      ">3 0.928 (0.075)\n",
      ">4 0.887 (0.115)\n",
      ">5 0.898 (0.102)\n",
      ">6 0.891 (0.110)\n",
      ">7 0.891 (0.114)\n",
      ">8 0.894 (0.105)\n",
      ">9 0.895 (0.096)\n",
      ">10 0.895 (0.091)\n",
      ">11 0.903 (0.081)\n",
      ">12 0.906 (0.083)\n",
      ">13 0.899 (0.089)\n",
      ">14 0.906 (0.083)\n",
      ">15 0.907 (0.083)\n",
      ">16 0.913 (0.086)\n",
      ">17 0.913 (0.086)\n",
      ">18 0.921 (0.088)\n",
      ">19 0.914 (0.086)\n",
      ">20 0.917 (0.087)\n",
      ">21 0.914 (0.086)\n",
      ">22 0.917 (0.087)\n",
      ">23 0.914 (0.086)\n",
      ">24 0.917 (0.087)\n",
      ">25 0.914 (0.086)\n",
      ">26 0.917 (0.087)\n",
      ">27 0.921 (0.088)\n",
      ">28 0.914 (0.086)\n",
      ">29 0.921 (0.084)\n",
      ">30 0.921 (0.084)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2fe330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 28.000\n",
      "Column: 1, Selected False, Rank: 2.000\n",
      "Column: 2, Selected False, Rank: 14.000\n",
      "Column: 3, Selected False, Rank: 27.000\n",
      "Column: 4, Selected False, Rank: 24.000\n",
      "Column: 5, Selected False, Rank: 13.000\n",
      "Column: 6, Selected False, Rank: 17.000\n",
      "Column: 7, Selected True, Rank: 1.000\n",
      "Column: 8, Selected False, Rank: 6.000\n",
      "Column: 9, Selected False, Rank: 19.000\n",
      "Column: 10, Selected False, Rank: 8.000\n",
      "Column: 11, Selected False, Rank: 20.000\n",
      "Column: 12, Selected False, Rank: 10.000\n",
      "Column: 13, Selected False, Rank: 22.000\n",
      "Column: 14, Selected True, Rank: 1.000\n",
      "Column: 15, Selected False, Rank: 5.000\n",
      "Column: 16, Selected False, Rank: 3.000\n",
      "Column: 17, Selected False, Rank: 25.000\n",
      "Column: 18, Selected False, Rank: 12.000\n",
      "Column: 19, Selected False, Rank: 26.000\n",
      "Column: 20, Selected False, Rank: 21.000\n",
      "Column: 21, Selected False, Rank: 7.000\n",
      "Column: 22, Selected True, Rank: 1.000\n",
      "Column: 23, Selected False, Rank: 23.000\n",
      "Column: 24, Selected False, Rank: 16.000\n",
      "Column: 25, Selected False, Rank: 18.000\n",
      "Column: 26, Selected False, Rank: 15.000\n",
      "Column: 27, Selected False, Rank: 11.000\n",
      "Column: 28, Selected False, Rank: 9.000\n",
      "Column: 29, Selected False, Rank: 4.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntj5\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ntj5\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ntj5\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(estimator=LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1'), n_features_to_select=3)\n",
    "rfe.fit(data_1,target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad8b28d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 27.000\n",
      "Column: 1, Selected False, Rank: 13.000\n",
      "Column: 2, Selected False, Rank: 2.000\n",
      "Column: 3, Selected False, Rank: 22.000\n",
      "Column: 4, Selected False, Rank: 21.000\n",
      "Column: 5, Selected False, Rank: 7.000\n",
      "Column: 6, Selected False, Rank: 9.000\n",
      "Column: 7, Selected True, Rank: 1.000\n",
      "Column: 8, Selected False, Rank: 15.000\n",
      "Column: 9, Selected False, Rank: 19.000\n",
      "Column: 10, Selected False, Rank: 11.000\n",
      "Column: 11, Selected False, Rank: 18.000\n",
      "Column: 12, Selected False, Rank: 14.000\n",
      "Column: 13, Selected False, Rank: 23.000\n",
      "Column: 14, Selected False, Rank: 4.000\n",
      "Column: 15, Selected True, Rank: 1.000\n",
      "Column: 16, Selected True, Rank: 1.000\n",
      "Column: 17, Selected False, Rank: 24.000\n",
      "Column: 18, Selected False, Rank: 8.000\n",
      "Column: 19, Selected False, Rank: 26.000\n",
      "Column: 20, Selected False, Rank: 25.000\n",
      "Column: 21, Selected False, Rank: 16.000\n",
      "Column: 22, Selected False, Rank: 3.000\n",
      "Column: 23, Selected False, Rank: 20.000\n",
      "Column: 24, Selected False, Rank: 12.000\n",
      "Column: 25, Selected False, Rank: 17.000\n",
      "Column: 26, Selected False, Rank: 10.000\n",
      "Column: 27, Selected False, Rank: 6.000\n",
      "Column: 28, Selected False, Rank: 5.000\n",
      "Column: 29, Selected True, Rank: 1.000\n",
      "Feature Name: 243.123605/6.49, Index: 7, Rank: 1.000\n",
      "Feature Name: 301.215668/17.74, Index: 15, Rank: 1.000\n",
      "Feature Name: 295.263376/19.32, Index: 16, Rank: 1.000\n",
      "Feature Name: 435.201572/7.04, Index: 29, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear', C=100, penalty='l1'), n_features_to_select=4)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "elected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_BL_NEW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac82b9",
   "metadata": {},
   "source": [
    "### For PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff7fd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbbdd897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: PP\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1acc9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd8075ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "#print(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3829e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30,0,-10):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24e8df0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 0.996 (0.020)\n",
      ">20 0.993 (0.028)\n",
      ">10 0.989 (0.033)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21068346",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9634dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.964 (0.063)\n",
      ">2 0.964 (0.058)\n",
      ">3 0.964 (0.058)\n",
      ">4 0.967 (0.058)\n",
      ">5 0.971 (0.056)\n",
      ">6 0.971 (0.056)\n",
      ">7 0.971 (0.056)\n",
      ">8 0.971 (0.056)\n",
      ">9 0.981 (0.041)\n",
      ">10 0.989 (0.033)\n",
      ">11 0.993 (0.028)\n",
      ">12 0.989 (0.032)\n",
      ">13 0.989 (0.032)\n",
      ">14 0.989 (0.032)\n",
      ">15 0.989 (0.032)\n",
      ">16 0.989 (0.033)\n",
      ">17 0.993 (0.028)\n",
      ">18 0.989 (0.033)\n",
      ">19 0.989 (0.032)\n",
      ">20 0.993 (0.028)\n",
      ">21 0.993 (0.028)\n",
      ">22 0.993 (0.028)\n",
      ">23 0.993 (0.028)\n",
      ">24 0.993 (0.028)\n",
      ">25 0.993 (0.028)\n",
      ">26 0.989 (0.033)\n",
      ">27 0.993 (0.028)\n",
      ">28 0.996 (0.020)\n",
      ">29 0.996 (0.020)\n",
      ">30 0.996 (0.020)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=LogisticRegression(solver = 'liblinear', C = 100, penalty = 'l1'), n_features_to_select=1)\n",
    "rfe.fit(data_1,target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bab22353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 27.000\n",
      "Column: 1, Selected False, Rank: 15.000\n",
      "Column: 2, Selected False, Rank: 10.000\n",
      "Column: 3, Selected True, Rank: 1.000\n",
      "Column: 4, Selected False, Rank: 25.000\n",
      "Column: 5, Selected False, Rank: 2.000\n",
      "Column: 6, Selected True, Rank: 1.000\n",
      "Column: 7, Selected False, Rank: 24.000\n",
      "Column: 8, Selected False, Rank: 23.000\n",
      "Column: 9, Selected False, Rank: 11.000\n",
      "Column: 10, Selected False, Rank: 7.000\n",
      "Column: 11, Selected False, Rank: 21.000\n",
      "Column: 12, Selected False, Rank: 20.000\n",
      "Column: 13, Selected False, Rank: 19.000\n",
      "Column: 14, Selected False, Rank: 13.000\n",
      "Column: 15, Selected False, Rank: 12.000\n",
      "Column: 16, Selected False, Rank: 22.000\n",
      "Column: 17, Selected False, Rank: 5.000\n",
      "Column: 18, Selected False, Rank: 17.000\n",
      "Column: 19, Selected False, Rank: 4.000\n",
      "Column: 20, Selected False, Rank: 14.000\n",
      "Column: 21, Selected False, Rank: 9.000\n",
      "Column: 22, Selected False, Rank: 16.000\n",
      "Column: 23, Selected False, Rank: 3.000\n",
      "Column: 24, Selected False, Rank: 26.000\n",
      "Column: 25, Selected True, Rank: 1.000\n",
      "Column: 26, Selected False, Rank: 6.000\n",
      "Column: 27, Selected False, Rank: 18.000\n",
      "Column: 28, Selected False, Rank: 8.000\n",
      "Column: 29, Selected True, Rank: 1.000\n",
      "Feature Name: 496.246433/21.25, Index: 3, Rank: 1.000\n",
      "Feature Name: 529.279112/8.06, Index: 6, Rank: 1.000\n",
      "Feature Name: 389.104431/8.13, Index: 25, Rank: 1.000\n",
      "Feature Name: 435.201572/7.04, Index: 29, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear', C=100, penalty='l1'), n_features_to_select=4)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_PP.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449c59e",
   "metadata": {},
   "source": [
    "### For PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69fc2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "802c3061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: PG\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94646b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fae7e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "#print(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39fa6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30, 0, -10):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a0e4dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 0.945 (0.060)\n",
      ">20 0.945 (0.060)\n",
      ">10 0.916 (0.069)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4442d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2'), n_features_to_select=i)\n",
    "        model = LogisticRegression(solver = 'newton-cg', C = 100, penalty = 'l2')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81220843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.952 (0.044)\n",
      ">2 0.949 (0.051)\n",
      ">3 0.934 (0.053)\n",
      ">4 0.927 (0.060)\n",
      ">5 0.912 (0.062)\n",
      ">6 0.913 (0.075)\n",
      ">7 0.906 (0.075)\n",
      ">8 0.916 (0.069)\n",
      ">9 0.923 (0.068)\n",
      ">10 0.916 (0.069)\n",
      ">11 0.930 (0.067)\n",
      ">12 0.942 (0.060)\n",
      ">13 0.942 (0.060)\n",
      ">14 0.942 (0.060)\n",
      ">15 0.945 (0.060)\n",
      ">16 0.945 (0.060)\n",
      ">17 0.945 (0.060)\n",
      ">18 0.945 (0.060)\n",
      ">19 0.945 (0.060)\n",
      ">20 0.945 (0.060)\n",
      ">21 0.945 (0.060)\n",
      ">22 0.945 (0.060)\n",
      ">23 0.945 (0.060)\n",
      ">24 0.945 (0.060)\n",
      ">25 0.945 (0.060)\n",
      ">26 0.945 (0.060)\n",
      ">27 0.945 (0.060)\n",
      ">28 0.945 (0.060)\n",
      ">29 0.945 (0.060)\n",
      ">30 0.945 (0.060)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7bf37a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 5.000\n",
      "Column: 1, Selected False, Rank: 24.000\n",
      "Column: 2, Selected False, Rank: 6.000\n",
      "Column: 3, Selected False, Rank: 17.000\n",
      "Column: 4, Selected False, Rank: 12.000\n",
      "Column: 5, Selected False, Rank: 13.000\n",
      "Column: 6, Selected False, Rank: 25.000\n",
      "Column: 7, Selected False, Rank: 3.000\n",
      "Column: 8, Selected False, Rank: 2.000\n",
      "Column: 9, Selected False, Rank: 22.000\n",
      "Column: 10, Selected False, Rank: 7.000\n",
      "Column: 11, Selected False, Rank: 23.000\n",
      "Column: 12, Selected False, Rank: 11.000\n",
      "Column: 13, Selected False, Rank: 15.000\n",
      "Column: 14, Selected False, Rank: 16.000\n",
      "Column: 15, Selected False, Rank: 14.000\n",
      "Column: 16, Selected False, Rank: 21.000\n",
      "Column: 17, Selected True, Rank: 1.000\n",
      "Column: 18, Selected True, Rank: 1.000\n",
      "Column: 19, Selected True, Rank: 1.000\n",
      "Column: 20, Selected False, Rank: 9.000\n",
      "Column: 21, Selected False, Rank: 10.000\n",
      "Column: 22, Selected False, Rank: 20.000\n",
      "Column: 23, Selected False, Rank: 26.000\n",
      "Column: 24, Selected False, Rank: 19.000\n",
      "Column: 25, Selected True, Rank: 1.000\n",
      "Column: 26, Selected False, Rank: 18.000\n",
      "Column: 27, Selected False, Rank: 4.000\n",
      "Column: 28, Selected True, Rank: 1.000\n",
      "Column: 29, Selected False, Rank: 8.000\n",
      "Feature Name: 126.904941/20.82, Index: 17, Rank: 1.000\n",
      "Feature Name: 429.223492/10.13, Index: 18, Rank: 1.000\n",
      "Feature Name: 397.330809/15.57, Index: 19, Rank: 1.000\n",
      "Feature Name: 389.104431/8.13, Index: 25, Rank: 1.000\n",
      "Feature Name: 433.222417/8.54, Index: 28, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='newton-cg', C=100, penalty='l2'), n_features_to_select=5)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb382e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_PG.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a940412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
