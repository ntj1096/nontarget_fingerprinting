{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d9dce7",
   "metadata": {},
   "source": [
    "### Running RFE on RF (for source types that met BA threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7352eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refer to 231205-NTA-Paper2-Classifiers for previous code that includes tuning hyperparameters + performance evaluation\n",
    "#Importing libraries to open data and run RFE + model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pprint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#RF met BA threshold for GW, LL, WWTP, and PP so below are the RFE results for those sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc923cab",
   "metadata": {},
   "source": [
    "### For AFFF-GW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edeb4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c698469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: AFFF-GW\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (AFFF-GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b91e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0478104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.54570928 2.54570928 4.11539313 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 4.54451372 4.87498812 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 3.22038648 4.8459347  ... 2.54570928 2.54570928 2.54570928]\n",
      " ...\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.02475995 2.54570928 2.54570928]\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.2965849  2.54570928 2.93484187]\n",
      " [2.54570928 2.54570928 3.58667926 ... 3.33173239 2.54570928 2.54570928]]\n"
     ]
    }
   ],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "print(data_1)\n",
    "#data_1 = pd.DataFrame(data_1)\n",
    "#data_1.to_csv('log10_dat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0697b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 Features: 30, Balanced Accuracy: 0.812 (0.223)\n",
      ">20 Features: 20, Balanced Accuracy: 0.802 (0.225)\n",
      ">10 Features: 10, Balanced Accuracy: 0.817 (0.229)\n"
     ]
    }
   ],
   "source": [
    "#class_names=np.array([0.0,1.0])\n",
    "# Function to get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30, 0, -10):  # Start with 610 features and reduce by 2 at each step\n",
    "        # Define the pipeline with RFE and RandomForestClassifier\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s Features: %d, Balanced Accuracy: %.3f (%.3f)' % (name, int(name), np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39a66faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.693 (0.227)\n",
      ">2 0.709 (0.228)\n",
      ">3 0.726 (0.222)\n",
      ">4 0.789 (0.208)\n",
      ">5 0.810 (0.232)\n",
      ">6 0.783 (0.247)\n",
      ">7 0.804 (0.224)\n",
      ">8 0.827 (0.219)\n",
      ">9 0.791 (0.222)\n",
      ">10 0.798 (0.222)\n",
      ">11 0.817 (0.219)\n",
      ">12 0.804 (0.234)\n",
      ">13 0.825 (0.222)\n",
      ">14 0.827 (0.227)\n",
      ">15 0.810 (0.223)\n",
      ">16 0.827 (0.208)\n",
      ">17 0.827 (0.223)\n",
      ">18 0.823 (0.214)\n",
      ">19 0.819 (0.226)\n",
      ">20 0.815 (0.219)\n",
      ">21 0.827 (0.218)\n",
      ">22 0.787 (0.226)\n",
      ">23 0.839 (0.209)\n",
      ">24 0.802 (0.221)\n",
      ">25 0.817 (0.219)\n",
      ">26 0.808 (0.218)\n",
      ">27 0.825 (0.226)\n",
      ">28 0.825 (0.207)\n",
      ">29 0.810 (0.214)\n",
      ">30 0.815 (0.219)\n"
     ]
    }
   ],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7af5e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 4.000\n",
      "Column: 1, Selected True, Rank: 1.000\n",
      "Column: 2, Selected True, Rank: 1.000\n",
      "Column: 3, Selected False, Rank: 11.000\n",
      "Column: 4, Selected False, Rank: 16.000\n",
      "Column: 5, Selected False, Rank: 23.000\n",
      "Column: 6, Selected False, Rank: 13.000\n",
      "Column: 7, Selected False, Rank: 2.000\n",
      "Column: 8, Selected False, Rank: 8.000\n",
      "Column: 9, Selected False, Rank: 15.000\n",
      "Column: 10, Selected False, Rank: 5.000\n",
      "Column: 11, Selected False, Rank: 25.000\n",
      "Column: 12, Selected False, Rank: 7.000\n",
      "Column: 13, Selected False, Rank: 14.000\n",
      "Column: 14, Selected False, Rank: 21.000\n",
      "Column: 15, Selected False, Rank: 6.000\n",
      "Column: 16, Selected False, Rank: 9.000\n",
      "Column: 17, Selected False, Rank: 18.000\n",
      "Column: 18, Selected False, Rank: 28.000\n",
      "Column: 19, Selected False, Rank: 27.000\n",
      "Column: 20, Selected False, Rank: 29.000\n",
      "Column: 21, Selected False, Rank: 12.000\n",
      "Column: 22, Selected False, Rank: 3.000\n",
      "Column: 23, Selected False, Rank: 20.000\n",
      "Column: 24, Selected False, Rank: 22.000\n",
      "Column: 25, Selected False, Rank: 26.000\n",
      "Column: 26, Selected False, Rank: 24.000\n",
      "Column: 27, Selected False, Rank: 10.000\n",
      "Column: 28, Selected False, Rank: 19.000\n",
      "Column: 29, Selected False, Rank: 17.000\n",
      "Feature Name: 390.964442/9.69, Index: 1, Rank: 1.000\n",
      "Feature Name: 218.986076/7.21, Index: 2, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, max_features='sqrt'), n_features_to_select=2)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c89015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_GW_RF.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c1d1f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 2.000\n",
      "Column: 1, Selected True, Rank: 1.000\n",
      "Column: 2, Selected True, Rank: 1.000\n",
      "Column: 3, Selected False, Rank: 7.000\n",
      "Column: 4, Selected False, Rank: 12.000\n",
      "Column: 5, Selected False, Rank: 15.000\n",
      "Column: 6, Selected False, Rank: 13.000\n",
      "Column: 7, Selected True, Rank: 1.000\n",
      "Column: 8, Selected False, Rank: 3.000\n",
      "Column: 9, Selected False, Rank: 9.000\n",
      "Column: 10, Selected True, Rank: 1.000\n",
      "Column: 11, Selected False, Rank: 24.000\n",
      "Column: 12, Selected False, Rank: 5.000\n",
      "Column: 13, Selected False, Rank: 11.000\n",
      "Column: 14, Selected False, Rank: 17.000\n",
      "Column: 15, Selected False, Rank: 6.000\n",
      "Column: 16, Selected False, Rank: 8.000\n",
      "Column: 17, Selected False, Rank: 20.000\n",
      "Column: 18, Selected False, Rank: 25.000\n",
      "Column: 19, Selected False, Rank: 26.000\n",
      "Column: 20, Selected False, Rank: 22.000\n",
      "Column: 21, Selected False, Rank: 10.000\n",
      "Column: 22, Selected True, Rank: 1.000\n",
      "Column: 23, Selected False, Rank: 18.000\n",
      "Column: 24, Selected False, Rank: 14.000\n",
      "Column: 25, Selected False, Rank: 19.000\n",
      "Column: 26, Selected False, Rank: 16.000\n",
      "Column: 27, Selected False, Rank: 4.000\n",
      "Column: 28, Selected False, Rank: 21.000\n",
      "Column: 29, Selected False, Rank: 23.000\n",
      "Feature Name: 390.964442/9.69, Index: 1, Rank: 1.000\n",
      "Feature Name: 218.986076/7.21, Index: 2, Rank: 1.000\n",
      "Feature Name: 243.123605/6.49, Index: 7, Rank: 1.000\n",
      "Feature Name: 251.164574/8.66, Index: 10, Rank: 1.000\n",
      "Feature Name: 132.056597/7.15, Index: 22, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, max_features='sqrt'), n_features_to_select=5)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05347f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2247283",
   "metadata": {},
   "source": [
    "### LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5393d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913c75b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: LL\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (AFFF-GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e8283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9db288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.54570928 2.54570928 4.11539313 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 4.54451372 4.87498812 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 3.22038648 4.8459347  ... 2.54570928 2.54570928 2.54570928]\n",
      " ...\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.02475995 2.54570928 2.54570928]\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.2965849  2.54570928 2.93484187]\n",
      " [2.54570928 2.54570928 3.58667926 ... 3.33173239 2.54570928 2.54570928]]\n"
     ]
    }
   ],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "print(data_1)\n",
    "#data_1 = pd.DataFrame(data_1)\n",
    "#data_1.to_csv('log10_dat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996630b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 Features: 30, Balanced Accuracy: 0.925 (0.131)\n",
      ">20 Features: 20, Balanced Accuracy: 0.925 (0.115)\n",
      ">10 Features: 10, Balanced Accuracy: 0.925 (0.131)\n"
     ]
    }
   ],
   "source": [
    "#class_names=np.array([0.0,1.0])\n",
    "# Function to get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30, 0, -10):  # Start with 610 features and reduce by 2 at each step\n",
    "        # Define the pipeline with RFE and RandomForestClassifier\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s Features: %d, Balanced Accuracy: %.3f (%.3f)' % (name, int(name), np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dd3247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.832 (0.161)\n",
      ">2 0.829 (0.151)\n",
      ">3 0.863 (0.142)\n",
      ">4 0.924 (0.109)\n",
      ">5 0.907 (0.134)\n",
      ">6 0.920 (0.131)\n",
      ">7 0.912 (0.133)\n",
      ">8 0.923 (0.131)\n",
      ">9 0.925 (0.131)\n",
      ">10 0.925 (0.131)\n",
      ">11 0.917 (0.134)\n",
      ">12 0.925 (0.131)\n",
      ">13 0.920 (0.113)\n",
      ">14 0.923 (0.131)\n",
      ">15 0.925 (0.131)\n",
      ">16 0.925 (0.131)\n",
      ">17 0.931 (0.110)\n",
      ">18 0.908 (0.137)\n",
      ">19 0.925 (0.131)\n",
      ">20 0.929 (0.127)\n",
      ">21 0.933 (0.111)\n",
      ">22 0.921 (0.113)\n",
      ">23 0.920 (0.130)\n",
      ">24 0.923 (0.131)\n",
      ">25 0.923 (0.131)\n",
      ">26 0.937 (0.128)\n",
      ">27 0.933 (0.128)\n",
      ">28 0.925 (0.115)\n",
      ">29 0.925 (0.115)\n",
      ">30 0.900 (0.138)\n"
     ]
    }
   ],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2118869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 14.000\n",
      "Column: 1, Selected False, Rank: 10.000\n",
      "Column: 2, Selected False, Rank: 3.000\n",
      "Column: 3, Selected False, Rank: 11.000\n",
      "Column: 4, Selected False, Rank: 19.000\n",
      "Column: 5, Selected False, Rank: 9.000\n",
      "Column: 6, Selected False, Rank: 5.000\n",
      "Column: 7, Selected False, Rank: 2.000\n",
      "Column: 8, Selected True, Rank: 1.000\n",
      "Column: 9, Selected True, Rank: 1.000\n",
      "Column: 10, Selected True, Rank: 1.000\n",
      "Column: 11, Selected False, Rank: 20.000\n",
      "Column: 12, Selected True, Rank: 1.000\n",
      "Column: 13, Selected False, Rank: 6.000\n",
      "Column: 14, Selected False, Rank: 15.000\n",
      "Column: 15, Selected False, Rank: 13.000\n",
      "Column: 16, Selected False, Rank: 8.000\n",
      "Column: 17, Selected False, Rank: 24.000\n",
      "Column: 18, Selected False, Rank: 25.000\n",
      "Column: 19, Selected False, Rank: 27.000\n",
      "Column: 20, Selected False, Rank: 26.000\n",
      "Column: 21, Selected False, Rank: 4.000\n",
      "Column: 22, Selected False, Rank: 7.000\n",
      "Column: 23, Selected False, Rank: 16.000\n",
      "Column: 24, Selected False, Rank: 17.000\n",
      "Column: 25, Selected False, Rank: 23.000\n",
      "Column: 26, Selected False, Rank: 18.000\n",
      "Column: 27, Selected False, Rank: 12.000\n",
      "Column: 28, Selected False, Rank: 21.000\n",
      "Column: 29, Selected False, Rank: 22.000\n",
      "Feature Name: 163.076289/6.93, Index: 8, Rank: 1.000\n",
      "Feature Name: 341.160715/9.2, Index: 9, Rank: 1.000\n",
      "Feature Name: 251.164574/8.66, Index: 10, Rank: 1.000\n",
      "Feature Name: 241.180448/9.53, Index: 12, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, max_features='sqrt'), n_features_to_select=4)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03912677",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_LL_RF.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1516fef",
   "metadata": {},
   "source": [
    "### WWTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d715129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4720dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: WWTP\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (AFFF-GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae45720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fb9d64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "print(target_1)\n",
    "#data_1 = pd.DataFrame(data_1)\n",
    "#data_1.to_csv('log10_dat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "333fb033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.901 (0.138)\n",
      ">2 0.909 (0.134)\n",
      ">3 0.911 (0.131)\n",
      ">4 0.909 (0.135)\n",
      ">5 0.909 (0.135)\n",
      ">6 0.916 (0.133)\n",
      ">7 0.918 (0.134)\n",
      ">8 0.916 (0.137)\n",
      ">9 0.916 (0.137)\n",
      ">10 0.916 (0.137)\n",
      ">11 0.914 (0.140)\n",
      ">12 0.914 (0.140)\n",
      ">13 0.914 (0.140)\n",
      ">14 0.914 (0.140)\n",
      ">15 0.928 (0.130)\n",
      ">16 0.930 (0.131)\n",
      ">17 0.930 (0.131)\n",
      ">18 0.930 (0.131)\n",
      ">19 0.930 (0.131)\n",
      ">20 0.930 (0.131)\n",
      ">21 0.930 (0.131)\n",
      ">22 0.930 (0.131)\n",
      ">23 0.930 (0.131)\n",
      ">24 0.930 (0.131)\n",
      ">25 0.930 (0.131)\n",
      ">26 0.930 (0.131)\n",
      ">27 0.930 (0.131)\n",
      ">28 0.932 (0.131)\n",
      ">29 0.930 (0.131)\n",
      ">30 0.930 (0.131)\n"
     ]
    }
   ],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='log2'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=1000, max_features='log2')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b20da889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 12.000\n",
      "Column: 1, Selected False, Rank: 22.000\n",
      "Column: 2, Selected False, Rank: 5.000\n",
      "Column: 3, Selected True, Rank: 1.000\n",
      "Column: 4, Selected False, Rank: 2.000\n",
      "Column: 5, Selected False, Rank: 19.000\n",
      "Column: 6, Selected False, Rank: 10.000\n",
      "Column: 7, Selected False, Rank: 7.000\n",
      "Column: 8, Selected False, Rank: 9.000\n",
      "Column: 9, Selected False, Rank: 25.000\n",
      "Column: 10, Selected False, Rank: 4.000\n",
      "Column: 11, Selected False, Rank: 24.000\n",
      "Column: 12, Selected False, Rank: 14.000\n",
      "Column: 13, Selected False, Rank: 15.000\n",
      "Column: 14, Selected False, Rank: 27.000\n",
      "Column: 15, Selected False, Rank: 13.000\n",
      "Column: 16, Selected False, Rank: 11.000\n",
      "Column: 17, Selected False, Rank: 26.000\n",
      "Column: 18, Selected False, Rank: 17.000\n",
      "Column: 19, Selected False, Rank: 28.000\n",
      "Column: 20, Selected False, Rank: 6.000\n",
      "Column: 21, Selected False, Rank: 3.000\n",
      "Column: 22, Selected True, Rank: 1.000\n",
      "Column: 23, Selected True, Rank: 1.000\n",
      "Column: 24, Selected False, Rank: 23.000\n",
      "Column: 25, Selected False, Rank: 21.000\n",
      "Column: 26, Selected False, Rank: 16.000\n",
      "Column: 27, Selected False, Rank: 8.000\n",
      "Column: 28, Selected False, Rank: 18.000\n",
      "Column: 29, Selected False, Rank: 20.000\n",
      "Feature Name: 496.246433/21.25, Index: 3, Rank: 1.000\n",
      "Feature Name: 132.056597/7.15, Index: 22, Rank: 1.000\n",
      "Feature Name: 500.27983/8.48, Index: 23, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='log2'), n_features_to_select=3)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2913f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_WWTP_RF.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1aca5",
   "metadata": {},
   "source": [
    "### PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4201300",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "465f77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: PP\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (AFFF-GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f272752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e6b5620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.54570928 2.54570928 4.11539313 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 4.54451372 4.87498812 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 3.22038648 4.8459347  ... 2.54570928 2.54570928 2.54570928]\n",
      " ...\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.02475995 2.54570928 2.54570928]\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.2965849  2.54570928 2.93484187]\n",
      " [2.54570928 2.54570928 3.58667926 ... 3.33173239 2.54570928 2.54570928]]\n"
     ]
    }
   ],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "print(data_1)\n",
    "#data_1 = pd.DataFrame(data_1)\n",
    "#data_1.to_csv('log10_dat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f695297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 Features: 30, Balanced Accuracy: 0.983 (0.062)\n",
      ">20 Features: 20, Balanced Accuracy: 0.967 (0.107)\n",
      ">10 Features: 10, Balanced Accuracy: 1.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "#class_names=np.array([0.0,1.0])\n",
    "# Function to get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30, 0, -10):  # Start with 610 features and reduce by 2 at each step\n",
    "        # Define the pipeline with RFE and RandomForestClassifier\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=1000, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s Features: %d, Balanced Accuracy: %.3f (%.3f)' % (name, int(name), np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90e18751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.840 (0.213)\n",
      ">2 0.943 (0.134)\n",
      ">3 0.985 (0.048)\n",
      ">4 0.960 (0.106)\n",
      ">5 0.985 (0.048)\n",
      ">6 0.996 (0.017)\n",
      ">7 0.992 (0.045)\n",
      ">8 0.992 (0.045)\n",
      ">9 1.000 (0.000)\n",
      ">10 1.000 (0.000)\n",
      ">11 1.000 (0.000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m results, names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 22\u001b[0m     scores \u001b[38;5;241m=\u001b[39m evaluate_model(model, data_1, target_1)\n\u001b[0;32m     23\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[0;32m     24\u001b[0m     names\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, X, y):\n\u001b[0;32m     13\u001b[0m     cv \u001b[38;5;241m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     scores \u001b[38;5;241m=\u001b[39m cross_val_score(model, data_1, target_1, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=1000, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4c318ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 11.000\n",
      "Column: 1, Selected False, Rank: 26.000\n",
      "Column: 2, Selected False, Rank: 4.000\n",
      "Column: 3, Selected False, Rank: 20.000\n",
      "Column: 4, Selected False, Rank: 15.000\n",
      "Column: 5, Selected False, Rank: 23.000\n",
      "Column: 6, Selected False, Rank: 22.000\n",
      "Column: 7, Selected False, Rank: 8.000\n",
      "Column: 8, Selected False, Rank: 13.000\n",
      "Column: 9, Selected False, Rank: 24.000\n",
      "Column: 10, Selected False, Rank: 12.000\n",
      "Column: 11, Selected False, Rank: 14.000\n",
      "Column: 12, Selected False, Rank: 6.000\n",
      "Column: 13, Selected False, Rank: 19.000\n",
      "Column: 14, Selected False, Rank: 25.000\n",
      "Column: 15, Selected False, Rank: 17.000\n",
      "Column: 16, Selected False, Rank: 7.000\n",
      "Column: 17, Selected False, Rank: 28.000\n",
      "Column: 18, Selected False, Rank: 5.000\n",
      "Column: 19, Selected False, Rank: 27.000\n",
      "Column: 20, Selected False, Rank: 21.000\n",
      "Column: 21, Selected False, Rank: 16.000\n",
      "Column: 22, Selected False, Rank: 10.000\n",
      "Column: 23, Selected False, Rank: 18.000\n",
      "Column: 24, Selected False, Rank: 9.000\n",
      "Column: 25, Selected True, Rank: 1.000\n",
      "Column: 26, Selected False, Rank: 2.000\n",
      "Column: 27, Selected False, Rank: 3.000\n",
      "Column: 28, Selected True, Rank: 1.000\n",
      "Column: 29, Selected True, Rank: 1.000\n",
      "Feature Name: 389.104431/8.13, Index: 25, Rank: 1.000\n",
      "Feature Name: 433.222417/8.54, Index: 28, Rank: 1.000\n",
      "Feature Name: 435.201572/7.04, Index: 29, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=3)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6883fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_PP_RF.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9414340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 8.000\n",
      "Column: 1, Selected False, Rank: 24.000\n",
      "Column: 2, Selected False, Rank: 2.000\n",
      "Column: 3, Selected False, Rank: 15.000\n",
      "Column: 4, Selected False, Rank: 11.000\n",
      "Column: 5, Selected False, Rank: 22.000\n",
      "Column: 6, Selected False, Rank: 20.000\n",
      "Column: 7, Selected False, Rank: 6.000\n",
      "Column: 8, Selected False, Rank: 10.000\n",
      "Column: 9, Selected False, Rank: 21.000\n",
      "Column: 10, Selected False, Rank: 13.000\n",
      "Column: 11, Selected False, Rank: 12.000\n",
      "Column: 12, Selected False, Rank: 5.000\n",
      "Column: 13, Selected False, Rank: 19.000\n",
      "Column: 14, Selected False, Rank: 23.000\n",
      "Column: 15, Selected False, Rank: 18.000\n",
      "Column: 16, Selected False, Rank: 4.000\n",
      "Column: 17, Selected False, Rank: 26.000\n",
      "Column: 18, Selected False, Rank: 3.000\n",
      "Column: 19, Selected False, Rank: 25.000\n",
      "Column: 20, Selected False, Rank: 14.000\n",
      "Column: 21, Selected False, Rank: 16.000\n",
      "Column: 22, Selected False, Rank: 9.000\n",
      "Column: 23, Selected False, Rank: 17.000\n",
      "Column: 24, Selected False, Rank: 7.000\n",
      "Column: 25, Selected True, Rank: 1.000\n",
      "Column: 26, Selected True, Rank: 1.000\n",
      "Column: 27, Selected True, Rank: 1.000\n",
      "Column: 28, Selected True, Rank: 1.000\n",
      "Column: 29, Selected True, Rank: 1.000\n",
      "Feature Name: 389.104431/8.13, Index: 25, Rank: 1.000\n",
      "Feature Name: 451.160341/6.26, Index: 26, Rank: 1.000\n",
      "Feature Name: 383.351251/19.64, Index: 27, Rank: 1.000\n",
      "Feature Name: 433.222417/8.54, Index: 28, Rank: 1.000\n",
      "Feature Name: 435.201572/7.04, Index: 29, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=5)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16ce45b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 5.000\n",
      "Column: 1, Selected False, Rank: 20.000\n",
      "Column: 2, Selected True, Rank: 1.000\n",
      "Column: 3, Selected False, Rank: 10.000\n",
      "Column: 4, Selected False, Rank: 9.000\n",
      "Column: 5, Selected False, Rank: 16.000\n",
      "Column: 6, Selected False, Rank: 15.000\n",
      "Column: 7, Selected True, Rank: 1.000\n",
      "Column: 8, Selected False, Rank: 7.000\n",
      "Column: 9, Selected False, Rank: 18.000\n",
      "Column: 10, Selected False, Rank: 6.000\n",
      "Column: 11, Selected False, Rank: 8.000\n",
      "Column: 12, Selected True, Rank: 1.000\n",
      "Column: 13, Selected False, Rank: 14.000\n",
      "Column: 14, Selected False, Rank: 19.000\n",
      "Column: 15, Selected False, Rank: 17.000\n",
      "Column: 16, Selected False, Rank: 2.000\n",
      "Column: 17, Selected False, Rank: 22.000\n",
      "Column: 18, Selected True, Rank: 1.000\n",
      "Column: 19, Selected False, Rank: 21.000\n",
      "Column: 20, Selected False, Rank: 11.000\n",
      "Column: 21, Selected False, Rank: 12.000\n",
      "Column: 22, Selected False, Rank: 4.000\n",
      "Column: 23, Selected False, Rank: 13.000\n",
      "Column: 24, Selected False, Rank: 3.000\n",
      "Column: 25, Selected True, Rank: 1.000\n",
      "Column: 26, Selected True, Rank: 1.000\n",
      "Column: 27, Selected True, Rank: 1.000\n",
      "Column: 28, Selected True, Rank: 1.000\n",
      "Column: 29, Selected True, Rank: 1.000\n",
      "Feature Name: 218.986076/7.21, Index: 2, Rank: 1.000\n",
      "Feature Name: 243.123605/6.49, Index: 7, Rank: 1.000\n",
      "Feature Name: 241.180448/9.53, Index: 12, Rank: 1.000\n",
      "Feature Name: 429.223492/10.13, Index: 18, Rank: 1.000\n",
      "Feature Name: 389.104431/8.13, Index: 25, Rank: 1.000\n",
      "Feature Name: 451.160341/6.26, Index: 26, Rank: 1.000\n",
      "Feature Name: 383.351251/19.64, Index: 27, Rank: 1.000\n",
      "Feature Name: 433.222417/8.54, Index: 28, Rank: 1.000\n",
      "Feature Name: 435.201572/7.04, Index: 29, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=9)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c83519ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(r'240617-NTA-AVG-EUC-30-CLOSEST-FEATURE-logT.csv', header=0) #Targets: 92 samples X 581 features\n",
    "#del data_rf[data_rf.columns[0]] #Dropping sample information\n",
    "#print(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "175a2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source type of interest: PG\n"
     ]
    }
   ],
   "source": [
    "#Prompt user for source type of interest (AFFF-GW, LF, BSL, WWTP, PP or PG)\n",
    "preferred_type = input(\"Enter the source type of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a128d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulating data frame based on user input to make \"Type\" column read 1 for all samples of source of interest and 0 for all other samples\n",
    "#Set up for binary classification (one-vs-all format)\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def set_type(row):\n",
    "    if row['Type'] == preferred_type:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create a new column \"Type 2\" with the updated values\n",
    "data_rf['Type_2'] = data_rf.apply(set_type, axis=1)\n",
    "del data_rf[data_rf.columns[0]] #Dropping original type column\n",
    "#Reordering columns with Type_2 as first column\n",
    "cols = list(data_rf.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "data_rf = data_rf[cols]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file (if needed)\n",
    "data_rf.to_csv('sample_data_with_labels_NEW10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ce42ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.54570928 2.54570928 4.11539313 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 4.54451372 4.87498812 ... 2.54570928 2.54570928 2.54570928]\n",
      " [2.54570928 3.22038648 4.8459347  ... 2.54570928 2.54570928 2.54570928]\n",
      " ...\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.02475995 2.54570928 2.54570928]\n",
      " [2.54570928 2.54570928 2.54570928 ... 3.2965849  2.54570928 2.93484187]\n",
      " [2.54570928 2.54570928 3.58667926 ... 3.33173239 2.54570928 2.54570928]]\n"
     ]
    }
   ],
   "source": [
    "#Changing pandas data frame to numpy for use in ML\n",
    "data_rf_np = data_rf.to_numpy()\n",
    "target_1 = data_rf_np[:,0].reshape(-1,1) #Convert target variables to 2D-array for sci-kit learn\n",
    "data_1 = data_rf_np[:,1:]\n",
    "\n",
    "#class_names=np.array([0.0,1.0])\n",
    "#print(data_1.shape)\n",
    "print(data_1)\n",
    "#data_1 = pd.DataFrame(data_1)\n",
    "#data_1.to_csv('log10_dat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcf6f16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">30 Features: 30, Balanced Accuracy: 0.854 (0.227)\n",
      ">20 Features: 20, Balanced Accuracy: 0.875 (0.217)\n",
      ">10 Features: 10, Balanced Accuracy: 0.917 (0.186)\n"
     ]
    }
   ],
   "source": [
    "#class_names=np.array([0.0,1.0])\n",
    "# Function to get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(30, 0, -10):  # Start with 610 features and reduce by 2 at each step\n",
    "        # Define the pipeline with RFE and RandomForestClassifier\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=1000, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s Features: %d, Balanced Accuracy: %.3f (%.3f)' % (name, int(name), np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b05e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.496 (0.018)\n",
      ">2 0.636 (0.218)\n",
      ">3 0.822 (0.229)\n",
      ">4 0.782 (0.240)\n",
      ">5 0.829 (0.233)\n",
      ">6 0.875 (0.217)\n",
      ">7 0.917 (0.186)\n",
      ">8 0.896 (0.203)\n",
      ">9 0.896 (0.203)\n",
      ">10 0.938 (0.165)\n",
      ">11 0.875 (0.217)\n",
      ">12 0.917 (0.186)\n",
      ">13 0.833 (0.236)\n",
      ">14 0.833 (0.236)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m results, names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 22\u001b[0m     scores \u001b[38;5;241m=\u001b[39m evaluate_model(model, data_1, target_1)\n\u001b[0;32m     23\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[0;32m     24\u001b[0m     names\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "Cell \u001b[1;32mIn[37], line 14\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, X, y):\n\u001b[0;32m     13\u001b[0m     cv \u001b[38;5;241m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     scores \u001b[38;5;241m=\u001b[39m cross_val_score(model, data_1, target_1, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Since this meets BA threshold. Let us run a quick RFE with large steps to estimate the exact number of features to retain\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1, 31):\n",
    "        rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=i)\n",
    "        model = RandomForestClassifier(n_estimators=1000, max_features='sqrt')\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "#Evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, data_1, target_1, scoring='balanced_accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, data_1, target_1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55395b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 16.000\n",
      "Column: 1, Selected False, Rank: 26.000\n",
      "Column: 2, Selected False, Rank: 8.000\n",
      "Column: 3, Selected False, Rank: 22.000\n",
      "Column: 4, Selected False, Rank: 18.000\n",
      "Column: 5, Selected False, Rank: 15.000\n",
      "Column: 6, Selected False, Rank: 6.000\n",
      "Column: 7, Selected False, Rank: 3.000\n",
      "Column: 8, Selected False, Rank: 11.000\n",
      "Column: 9, Selected False, Rank: 28.000\n",
      "Column: 10, Selected False, Rank: 9.000\n",
      "Column: 11, Selected False, Rank: 25.000\n",
      "Column: 12, Selected False, Rank: 10.000\n",
      "Column: 13, Selected False, Rank: 19.000\n",
      "Column: 14, Selected False, Rank: 27.000\n",
      "Column: 15, Selected False, Rank: 12.000\n",
      "Column: 16, Selected False, Rank: 5.000\n",
      "Column: 17, Selected True, Rank: 1.000\n",
      "Column: 18, Selected True, Rank: 1.000\n",
      "Column: 19, Selected True, Rank: 1.000\n",
      "Column: 20, Selected False, Rank: 4.000\n",
      "Column: 21, Selected False, Rank: 23.000\n",
      "Column: 22, Selected False, Rank: 7.000\n",
      "Column: 23, Selected False, Rank: 14.000\n",
      "Column: 24, Selected False, Rank: 17.000\n",
      "Column: 25, Selected False, Rank: 20.000\n",
      "Column: 26, Selected False, Rank: 21.000\n",
      "Column: 27, Selected False, Rank: 2.000\n",
      "Column: 28, Selected False, Rank: 24.000\n",
      "Column: 29, Selected False, Rank: 13.000\n",
      "Feature Name: 126.904941/20.82, Index: 17, Rank: 1.000\n",
      "Feature Name: 429.223492/10.13, Index: 18, Rank: 1.000\n",
      "Feature Name: 397.330809/15.57, Index: 19, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=3)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21c65292",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.DataFrame({\n",
    "    'Feature Name': [feature_names[index] for index in selected_feature_indices]\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "selected_features_df.to_excel(\"RFE_selected_features_norm_PG_RF.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15ebcc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 10.000\n",
      "Column: 1, Selected False, Rank: 20.000\n",
      "Column: 2, Selected False, Rank: 5.000\n",
      "Column: 3, Selected False, Rank: 19.000\n",
      "Column: 4, Selected False, Rank: 13.000\n",
      "Column: 5, Selected False, Rank: 11.000\n",
      "Column: 6, Selected False, Rank: 4.000\n",
      "Column: 7, Selected True, Rank: 1.000\n",
      "Column: 8, Selected False, Rank: 9.000\n",
      "Column: 9, Selected False, Rank: 25.000\n",
      "Column: 10, Selected False, Rank: 6.000\n",
      "Column: 11, Selected False, Rank: 21.000\n",
      "Column: 12, Selected False, Rank: 7.000\n",
      "Column: 13, Selected False, Rank: 16.000\n",
      "Column: 14, Selected False, Rank: 24.000\n",
      "Column: 15, Selected False, Rank: 8.000\n",
      "Column: 16, Selected False, Rank: 2.000\n",
      "Column: 17, Selected True, Rank: 1.000\n",
      "Column: 18, Selected True, Rank: 1.000\n",
      "Column: 19, Selected True, Rank: 1.000\n",
      "Column: 20, Selected True, Rank: 1.000\n",
      "Column: 21, Selected False, Rank: 23.000\n",
      "Column: 22, Selected False, Rank: 3.000\n",
      "Column: 23, Selected False, Rank: 12.000\n",
      "Column: 24, Selected False, Rank: 17.000\n",
      "Column: 25, Selected False, Rank: 15.000\n",
      "Column: 26, Selected False, Rank: 18.000\n",
      "Column: 27, Selected True, Rank: 1.000\n",
      "Column: 28, Selected False, Rank: 22.000\n",
      "Column: 29, Selected False, Rank: 14.000\n",
      "Feature Name: 243.123605/6.49, Index: 7, Rank: 1.000\n",
      "Feature Name: 126.904941/20.82, Index: 17, Rank: 1.000\n",
      "Feature Name: 429.223492/10.13, Index: 18, Rank: 1.000\n",
      "Feature Name: 397.330809/15.57, Index: 19, Rank: 1.000\n",
      "Feature Name: 141.016697/15.71, Index: 20, Rank: 1.000\n",
      "Feature Name: 383.351251/19.64, Index: 27, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=6)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ac90e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 10.000\n",
      "Column: 1, Selected False, Rank: 22.000\n",
      "Column: 2, Selected False, Rank: 4.000\n",
      "Column: 3, Selected False, Rank: 18.000\n",
      "Column: 4, Selected False, Rank: 13.000\n",
      "Column: 5, Selected False, Rank: 8.000\n",
      "Column: 6, Selected False, Rank: 2.000\n",
      "Column: 7, Selected True, Rank: 1.000\n",
      "Column: 8, Selected False, Rank: 7.000\n",
      "Column: 9, Selected False, Rank: 24.000\n",
      "Column: 10, Selected False, Rank: 5.000\n",
      "Column: 11, Selected False, Rank: 19.000\n",
      "Column: 12, Selected False, Rank: 6.000\n",
      "Column: 13, Selected False, Rank: 15.000\n",
      "Column: 14, Selected False, Rank: 23.000\n",
      "Column: 15, Selected False, Rank: 11.000\n",
      "Column: 16, Selected True, Rank: 1.000\n",
      "Column: 17, Selected True, Rank: 1.000\n",
      "Column: 18, Selected True, Rank: 1.000\n",
      "Column: 19, Selected True, Rank: 1.000\n",
      "Column: 20, Selected True, Rank: 1.000\n",
      "Column: 21, Selected False, Rank: 20.000\n",
      "Column: 22, Selected False, Rank: 3.000\n",
      "Column: 23, Selected False, Rank: 9.000\n",
      "Column: 24, Selected False, Rank: 17.000\n",
      "Column: 25, Selected False, Rank: 14.000\n",
      "Column: 26, Selected False, Rank: 16.000\n",
      "Column: 27, Selected True, Rank: 1.000\n",
      "Column: 28, Selected False, Rank: 21.000\n",
      "Column: 29, Selected False, Rank: 12.000\n",
      "Feature Name: 243.123605/6.49, Index: 7, Rank: 1.000\n",
      "Feature Name: 295.263376/19.32, Index: 16, Rank: 1.000\n",
      "Feature Name: 126.904941/20.82, Index: 17, Rank: 1.000\n",
      "Feature Name: 429.223492/10.13, Index: 18, Rank: 1.000\n",
      "Feature Name: 397.330809/15.57, Index: 19, Rank: 1.000\n",
      "Feature Name: 141.016697/15.71, Index: 20, Rank: 1.000\n",
      "Feature Name: 383.351251/19.64, Index: 27, Rank: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for feature selection\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=1000, max_features='sqrt'), n_features_to_select=7)\n",
    "rfe.fit(data_1, target_1.ravel())\n",
    "for i in range(data_1.shape[1]):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "# Load feature names from the second dataset\n",
    "labels_dat = pd.read_csv(\"240128-NTA-Normalized-Labels-Feature.csv\")\n",
    "feature_names = labels_dat.columns\n",
    "\n",
    "# Print selected features with their names\n",
    "selected_feature_indices = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n",
    "\n",
    "for index in selected_feature_indices:\n",
    "    print('Feature Name: %s, Index: %d, Rank: %.3f' % (feature_names[index], index, rfe.ranking_[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8a6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
